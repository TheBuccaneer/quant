### Required prerequisites

- [X] Consult the [security policy](https://github.com/NVIDIA/cuda-quantum/security/policy). If reporting a security vulnerability, do not report the bug using this form. Use the process described in the policy to report the issue.
- [X] Make sure you've read the [documentation](https://nvidia.github.io/cuda-quantum/latest). Your issue may be addressed there.
- [X] Search the [issue tracker](https://github.com/NVIDIA/cuda-quantum/issues) to verify that this hasn't already been reported. +1 or comment there if it has.
- [X] If possible, make a PR with a failing test to give us a starting point to work on!

### Describe the bug

Running `cudaq.observe` causes a memory leak. I think this is similar to the issue in https://github.com/NVIDIA/cuda-quantum/issues/1770. 

### Steps to reproduce the bug

```python
# Utility function for printing memory usage
def print_memory_usage(message):
    process = psutil.Process(os.getpid())
    mem_info = process.memory_info()
    mem_usage_mb = mem_info.rss / (1024 ** 2)  # Convert to MB
    print(f"\r{message}, Memory Usage: {mem_usage_mb:.2f} MB", end="")
```
```python
# Sample kernel I was using for my model
kernel, thetas = cudaq.make_kernel(list)
qubit_count = 1 # Set to 1 for now
qubits = kernel.qalloc(qubit_count)

# Apply variational gate parameters optimized during training
for i in range(qubit_count):
    kernel.rx(thetas[2 * i], qubits[i])
    kernel.rz(thetas[2 * i + 1], qubits[i])

# Entangle the qubits
for i in range(1, qubit_count):
    kernel.cx(qubits[i], qubits[i - 1])

pauli_z_hamiltonians = [spin.z(i) for i in range(qubit_count)]
```
```python
for i in range(100000):
    print_memory_usage(f"Iteration {i}")

    hamiltonians = pauli_z_hamiltonians

    # result = cudaq.observe(kernel, spin.z(0), [0.5, 0.5])
    for hamiltonian in hamiltonians:
        cudaq.observe(kernel, hamiltonian, [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5])
```

The memory keeps incrementally increasing without being deallocated.
```
Output: Iteration 99999, Memory Usage: 1220.81 MB << This keeps increasing slightly every iteration
```

Memory leak.
```
print_memory_usage(f"After testing")
```
```
Output: After testing, Memory Usage: 1220.81 MB << No deallocation
```

### Expected behavior

I thought that after running observe, used memory would get deallocated. I think this is an issue with the runtime module in general since Issue https://github.com/NVIDIA/cuda-quantum/issues/1770 also has this problem? I haven't looked at the source code that much yet.

### Is this a regression? If it is, put the last known working version (or commit) here.

Not a regression

### Environment

- **CUDA Quantum version**: CUDA-Q Version 0.7.1 (https://github.com/NVIDIA/cuda-quantum 1f8dd79d46cad9b9bd0eb220eb04408a2e6beda4)
- **Python version**: 3.10.12 (main, Nov 20 2023, 15:14:05) [GCC 11.4.0]
- **C++ compiler**: g++ (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0
- **Operating system**: Linux 6.1.85+


### Suggestions

_No response_