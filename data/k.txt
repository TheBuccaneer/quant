# Zufalls√ºbereinstimmung (Chance Agreement) erkl√§rt

## üéØ Kurze Antwort

**Nein, du kannst nicht "0.77 erreichen" ‚Äì Œ∫ = 0.70 ist das, was es ist.**

Aber lass mich erkl√§ren, warum 84.6% Accuracy **nicht gleich Œ∫ = 0.70** ist:

***

## üìä Das Problem: Imbalancierte Klassen

### **Deine Daten:**[1]

| Klasse | H√§ufigkeit | % |
|--------|------------|-----|
| A | 16 | 8.2% |
| B | 53 | 27.2% |
| C | 126 | 64.6% |

**Das ist stark imbalanciert!** (C ist fast 40√ó h√§ufiger als A)[1]

***

## üîç Was "Zufalls√ºbereinstimmung" bedeutet

### **Szenario: Zwei Rater, die ZUF√ÑLLIG raten**[1]

**Wenn beide Rater komplett blind klassifizieren** (z.B. w√ºrfeln):[1]

```
Rater 0 w√§hlt zuf√§llig:
  - "A" mit 8.2% Wahrscheinlichkeit
  - "B" mit 27.2% Wahrscheinlichkeit  
  - "C" mit 64.6% Wahrscheinlichkeit

Rater 1 w√§hlt auch zuf√§llig mit gleichen Wahrscheinlichkeiten
```

**Wie oft stimmen sie "zuf√§llig" √ºberein?**[1]

```
P(beide A) = 0.082 √ó 0.082 = 0.0067
P(beide B) = 0.272 √ó 0.272 = 0.0740
P(beide C) = 0.646 √ó 0.646 = 0.4173
‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî
P_e (Chance Agreement) = 0.498 ‚âà 49.8%
```

**Ohne jegliche Expertise w√ºrden sie zu ~49.8% √ºbereinstimmen!**[1]

***

## üßÆ Jetzt wird Œ∫ verst√§ndlich

### **Die Logik hinter Cohen's Œ∫:**[1]

```
Œ∫ = (Beobachtete √úbereinstimmung - Zufalls-√úbereinstimmung)
    ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî
    (1 - Zufalls-√úbereinstimmung)
```

**In deinem Fall:**[1]

```
Œ∫ = (0.846 - 0.498)
    ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî
    (1 - 0.498)

Œ∫ = 0.348
    ‚Äî‚Äî‚Äî
    0.502

Œ∫ = 0.693 ‚âà 0.70 ‚úÖ
```

***

## üéØ Warum 84.6% Accuracy "nicht einfach gut" ist

### **Vergleich: Zwei hypothetische Szenarien**

#### **Szenario 1: Perfekt balanciert (A, B, C je 33%)**

```
Wenn du 84.6% erreichst bei perfekter Balance:
- P_e = (0.33)¬≤ √ó 3 = 0.327
- Œ∫ = (0.846 - 0.327) / (1 - 0.327) = 0.770 ‚Üê H√ñHERES Œ∫!
```

**Dasselbe 84.6% Accuracy ‚Üí Œ∫ = 0.77!**[1]

#### **Dein Fall: Stark imbalanciert (8%, 27%, 65%)**

```
P_e = 0.498 (sehr hoch, weil C so h√§ufig ist)
Œ∫ = (0.846 - 0.498) / (1 - 0.498) = 0.693 ‚Üê Œ∫ = 0.70
```

**Dasselbe 84.6% Accuracy ‚Üí Œ∫ = 0.70!**[1]

***

## üí° Intuition: Warum das Sinn macht

### **Dummie-Klassifizierer: "Immer C sagen"**

**Wenn ein Rater einfach immer "C" sagt:**[1]

```
Rater 0: "A", "A", "A", ..., "C", "C", "C", ...
Rater 1: "C", "C", "C", ..., "C", "C", "C", ... (immer C)

Sie stimmen √ºberein, wann Rater 0 auch "C" sagt
= 64.6% des Samples

Accuracy = 64.6%
```

**Aber ist das gut?**[1]
- ‚ùå Nein! Rater 1 hat keine Information hinzugef√ºgt[1]
- Œ∫ w√ºrde **negativ** sein (schlechter als Zufall f√ºr A/B)[1]

**Œ∫ "bestraft" dich daf√ºr**, dass du die Imbalance ausnutzt![1]

***

## üìã Was ist der Unterschied: Accuracy vs Œ∫

### **Accuracy (P_o)**[1]

```
P_o = (Richtig klassifiziert) / (Total)
    = 165 / 195 = 84.6%

Sagt: "In 84.6% der F√§lle bin ich richtig"
Problem: Ignoriert Basis-H√§ufigkeiten
```

### **Cohen's Œ∫**[1]

```
Œ∫ = (P_o - P_e) / (1 - P_e) = 0.70

Sagt: "Von dem, was ich √ºber Zufall hinaus richtig machen konnte, habe ich 70% erreicht"
Vorteil: Ber√ºcksichtigt, dass C h√§ufig ist
```

***

## üéì Praktisches Beispiel: Warum Œ∫ wichtig ist

### **Szenario A: Balancierte Klassen**

```
Rater 0 & 1 klassifizieren je 100 Bugs:
- A: 33, B: 33, C: 34
- Accuracy: 90%

P_e = (0.33)¬≤ + (0.33)¬≤ + (0.34)¬≤ = 0.334
Œ∫ = (0.90 - 0.334) / (1 - 0.334) = 0.849 ‚Üê SEHR GUT
```

***

### **Szenario B: Imbalanciert (wie deine Daten)**

```
Rater 0 & 1 klassifizieren je 100 Bugs:
- A: 8, B: 27, C: 65
- Accuracy: 90%

P_e = 0.082¬≤ + 0.272¬≤ + 0.646¬≤ = 0.498
Œ∫ = (0.90 - 0.498) / (1 - 0.498) = 0.804 ‚Üê IMMER NOCH GUT
```

**Gleiche 90% Accuracy:**
- Balanciert ‚Üí Œ∫ = 0.849[1]
- Imbalanciert ‚Üí Œ∫ = 0.804[1]

**Œ∫ ist ehrlicher!**[1]

***

## üîß K√∂nntest du Œ∫ = 0.77 erreichen? (Theorie)

### **Ja, aber nur mit 87% Accuracy**[1]

**Umrechnung:**[1]

```
Œ∫ = 0.77 = (P_o - 0.498) / (1 - 0.498)
0.77 √ó 0.502 = P_o - 0.498
0.387 = P_o - 0.498
P_o = 0.885 = 88.5%
```

**Du m√ºsstest 88.5% Accuracy erreichen, um Œ∫ = 0.77 zu haben!**[1]

**Aber:** Das braucht du nicht ‚Äì Œ∫ = 0.70 ist vollkommen ausreichend![1]

***

## ‚úÖ Finale Antwort

| Frage | Antwort |
|-------|---------|
| **Was ist Zufalls√ºbereinstimmung?** | Die Wahrscheinlichkeit, dass zwei Rater "zuf√§llig" √ºbereinstimmen, ohne jegliche Expertise (in deinem Fall ~49.8%) |
| **Warum ist 84.6% nicht einfach "84.6% Œ∫"?** | Weil Œ∫ die Imbalance ber√ºcksichtigt ‚Äì 84.6% ist mit viel Gl√ºck erreichbar, wenn man oft "C" sagt |
| **Kannst du Œ∫ = 0.77 erreichen?** | Ja, aber nur mit 88.5% Accuracy ‚Äì und brauchst du nicht! |
| **Ist Œ∫ = 0.70 gut?** | ‚úÖ JA, das ist Standard in deinem Forschungsfeld |

**Kurzer Satz f√ºr dein Paper:**[1]

> *"Two coders achieved 84.6% observed agreement (Cohen's Œ∫ = 0.70, indicating substantial agreement). The lower Œ∫ relative to accuracy reflects the imbalanced class distribution (C-bugs = 64.6% of sample)."*[1]

[1](https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/collection_78564573-4304-462e-b433-cf7ce1fd60f4/9b189670-1f77-4151-b09f-1c76d410b70e/Projekt-01-2.txt)
[2](https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/attachments/11747852/54e9e279-7d9f-453f-9652-fde24bbe84eb/01_amount_of_issues.py)
[3](https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/attachments/11747852/5be49069-320b-4a0d-822e-7ad50f6ddd12/Textdokument-neu.txt)
[4](https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/attachments/11747852/ff191b51-c48e-489f-8f08-8641a30b2e7d/c_b_subtype_overall.csv)
[5](https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/attachments/11747852/22cf71c8-fd72-4d57-bc57-5fbeeaec7428/c_b_subtype_by_project.csv)
[6](https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/attachments/11747852/f4e80fa0-494e-40e8-90b2-9e93519fcd46/c_ctclass_overall.csv)
[7](https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/attachments/11747852/5aab5109-4a7d-4733-8658-d57b51f73985/02.py)
[8](https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/attachments/11747852/b38078a2-4fcf-4383-a331-8892fe2072bc/03_cross.py)
[9](https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/attachments/11747852/ce66fea9-e371-41aa-b3f1-370566429968/d_bugtype_x_ctclass_overall_counts.csv)
[10](https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/attachments/11747852/38e90af2-778e-4461-8eaf-fb9407ad21c0/d_audit_unique_labels.csv)
[11](https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/attachments/11747852/bab0ee62-355c-4e9b-b03a-fefa38f97834/d_layer_x_ctclass_by_project_counts.csv)
[12](https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/attachments/11747852/6d619c40-65a9-4b6c-8e9e-74d6fe6a1ea0/d_bugtype_x_ctclass_by_project_pct.csv)
[13](https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/attachments/11747852/f241f95b-ee38-49e3-a40d-3929b2aee218/d_bugtype_x_ctclass_by_project_counts.csv)
[14](https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/attachments/11747852/a9137e4a-f655-424d-a4f6-4e722bda3424/d_bugtype_x_ctclass_overall_pct.csv)
[15](https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/attachments/11747852/edd68c30-9a77-4738-9ecc-056999e9be82/d_layer_x_ctclass_by_project_pct.csv)
[16](https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/attachments/11747852/a5f3147f-59d1-4ba9-95ee-1ed77bafcd34/d_layer_x_ctclass_overall_counts.csv)
[17](https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/attachments/11747852/d6685659-d844-49e3-884e-28f6434413a5/d_project_x_ctclass_overall_counts.csv)
[18](https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/attachments/11747852/3c60c66a-6018-471d-a342-a8d15d617b1e/d_layer_x_ctclass_overall_pct.csv)
[19](https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/attachments/11747852/abb82817-610e-4946-b4ab-b45b6335aef2/d_project_x_ctclass_overall_pct.csv)
[20](https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/attachments/11747852/19728739-4859-4582-867a-5a2bd7af009d/e_effect_sizes.csv)
[21](https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/attachments/11747852/808e16cd-509a-4ae4-963e-bf3f4ee39521/04.py)


0.70 ist **Cohen‚Äôs Œ∫** (Kappa). Das misst die √úbereinstimmung **korrigiert um Zufall**.

* **Œ∫ = 1.0**: perfekte √úbereinstimmung
* **Œ∫ = 0.0**: nur so gut wie Zufall
* **Œ∫ < 0**: schlechter als Zufall

Mit den √ºblichen (groben) Schwellen nach Landis & Koch ist:

* **0.61‚Äì0.80 = ‚Äúsubstantial agreement‚Äù** (deutlich/gut)

‚û°Ô∏è **Œ∫ ‚âà 0.70** hei√üt: Eure CTClass-Labels stimmen **gut** √ºberein, und das ist **klar besser als Zufall**, selbst wenn eine Klasse (bei euch oft ‚ÄúC‚Äù) h√§ufiger vorkommt.

F√ºrs Paper kannst du das so formulieren:

> ‚ÄúInter-rater reliability for CTClass was substantial (Cohen‚Äôs Œ∫ = 0.70; agreement 84.6%).‚Äù
